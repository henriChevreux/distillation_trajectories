% Model Architecture Citations
\documentclass{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{array}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{natbib}
\bibliographystyle{abbrvnat}

\title{Academic Support for Model Architecture Choices}
\author{Distillation Trajectories Project}
\date{\today}

\begin{document}

\maketitle

\section{U-Net Architecture for Diffusion Models}

The U-Net architecture used in our diffusion models is directly supported by the seminal works in the field. The original DDPM paper by \citet{ho2020denoising} established U-Net as the standard architecture for diffusion models. This choice builds upon the work of \citet{ronneberger2015unet}, who introduced U-Net for image segmentation.

Our specific implementation with skip connections follows the approach outlined in \citet{dhariwal2021diffusion}, who improved the original U-Net architecture for diffusion models to achieve state-of-the-art results in image generation.

\section{Time Step Embeddings}

The sinusoidal position embeddings for encoding timesteps in our model are based on the approach from the Transformer architecture \citep{vaswani2017attention}. This choice was adopted by \citet{ho2020denoising} in the original DDPM paper and has become standard practice for diffusion models.

The specific implementation with a time-embedding MLP that projects the sinusoidal embeddings follows the implementation from \citet{nichol2021improved}, which showed that proper time embedding is crucial for model performance.

\section{Channel Dimensions and Model Scaling}

Our choice of channel dimensions and scaling factors is informed by several works:

\begin{itemize}
    \item The base channel dimension of 128 with channel multipliers of [1, 2, 2, 2] follows the architectural recommendations from \citet{dhariwal2021diffusion}, who conducted extensive experiments to find optimal architectures.
    
    \item The approach to downsampling student models with different size factors is supported by knowledge distillation literature such as \citet{hinton2015distilling}, and specifically for diffusion models by \citet{luhman2021knowledge} and \citet{salimans2022progressive}.
\end{itemize}

\section{Residual Blocks and Normalization}

The residual block design with two convolutional layers, batch normalization, and residual connections follows standard practice established by \citet{he2016deep} for ResNets and adapted for diffusion models by \citet{ho2020denoising} and \citet{nichol2021improved}.

The group normalization used in some implementations has been shown by \citet{kolesnikov2019big} to work better than batch normalization for generative models, particularly when combined with weight standardization.

\section{Student-Teacher Distillation Approach}

Our approach to distilling knowledge from teacher to student models is supported by several recent works in diffusion model distillation:

\begin{itemize}
    \item The concept of progressive distillation for diffusion models introduced by \citet{salimans2022progressive} provides the foundation for our distillation approach, where a model is trained to match outputs from a larger model.
    
    \item The specific scaling approach for student models of varying sizes is informed by \citet{luhman2021knowledge}, who explored different architectural choices for knowledge distillation in diffusion models.
    
    \item Recent work by \citet{song2023consistency} on consistency distillation also supports our approach of maintaining model quality while reducing sampling steps.
\end{itemize}

\section{Dropout Rate Selection}

The dropout rate of 0.3 used in our models is supported by empirical findings in \citet{nichol2021improved}, who found that appropriate dropout rates help diffusion models generalize better and prevent overfitting.

\section{Upsampling and Downsampling Methods}

Our choice of bilinear interpolation for upsampling and max pooling for downsampling is supported by standard practice in computer vision models and specifically for diffusion models by \citet{ho2020denoising} and \citet{dhariwal2021diffusion}.

\section{Conclusion}

The architectural choices made in our diffusion models are well-supported by academic literature, with each component having clear precedent in published research. These choices represent best practices for diffusion models and follow the evolution of architecture design in this rapidly developing field.

\bibliography{references}

\end{document} 